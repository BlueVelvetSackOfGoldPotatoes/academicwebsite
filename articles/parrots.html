<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Gonçalo Hora de Carvalho</title>
  <link rel="stylesheet" type="text/css" href='../style/style.css'>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <!-- Prism.js for code highlighting -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism.min.css" rel="stylesheet" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js"></script>
</head>
</head>

<body>
  <header id="banner">
    <h1>Gonçalo Hora de Carvalho</h1>
    <nav id="menu">
        <ul>
            <li>
                <a href="../index.html">WIPs</a>
                <ul class="dropdown">
                  <li><a href="o_truth.html#o-truth">O-Truth</a></li>
                  <li><a href="lcl.html#lego">LEGO Connect Language</a></li>
                  <li><a href="parrots.html#parrots-turing-trap">Parrots, the Turing Trap &amp; the problem of Artificial Dualism</a></li>
                  <li><a href="child_play.html#child-play">ChildPlay Benchmark</a></li>
                  <!-- Add other article links here -->
                </ul>
            </li>
            <li>
                <a href="../blog.html">Blog</a>
                <ul class="dropdown">
                  <li><a href="../blog.html#parrots">Parrots</a></li>
                  <li><a href="../blog.html#artificial_dualism">Artificial Dualism</a></li>
                  <li><a href="../blog.html#black_boxes">Black Boxes R NOT Pitch Black</a></li>
                  <li><a href="../blog.html#turing_trap">TTT</a></li>
                  <li><a href="../blog.html#language">On Language</a></li>
                </ul>
            </li>
            <li>
                <a href="../about.html">About</a>
            </li>
        </ul>
    </nav>
  </header>

  <article id="parrots-turing-trap">
    <header><h2 style="text-align: center;">Parrots, the Turing Trap &amp; the problem of Artificial Dualism</header></h2>
    <header><h4 style="text-align: center;">2024</header></h4>
      <p>
        If it looks like a duck, swims like a duck, and quacks like a duck, then your LLM's priors likely classify it as a duck based on learned data patterns matching the input. LLMs such as the DeepSeek, GPT, Gemini, Claude, Mistral, and LLama models, amongst many others following the transformer architecture may very well sound like a person, but they do not function like one. Recent developments have often been accompanied by claims of advanced reasoning and understanding. Words such as “reasoning”, “general”, “understanding”, “intelligent”, and even “conscious” are used interchangeably as marketing mixes with the confirmation bias–laden public. We argue the case that not only are terms being misused and stretched beyond their meaning, but the claims are also theoretically and technically false, and demonstrably so. In this paper, we propose that these assertions stem from a misinterpretation of advanced pattern-matching as genuine cognitive processing-a phenomenon we call the “Turing Trap”. We further identify an “Artificial Dualism Problem” (ADP), wherein observers imbue neural networks with human-like mental states simply because the models can emulate human language. Furthermore, by comparing the architectures and algorithms underlying LLMs to human neurobiology, we believe we can show that these models currently lack the critical structures and processes responsible for conscious thought, flexible reasoning, and self-awareness.
      </p>
  </article>

</main>

<footer>
  <!-- <p><a href="#banner">Return to Top</a></p> -->
</footer>
</body>
</html>